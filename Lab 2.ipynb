{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zgc87rWWCg9e"
   },
   "source": [
    "# ================================================\n",
    "# Laboratorio 2 — Similitud de Coseno\n",
    "# ================================================\n",
    "\n",
    "# Instrucciones\n",
    "1. **Carga de embeddings**  \n",
    "   - Utilizar las representaciones vectoriales preentrenadas (*GloVe 100d*).  \n",
    "   - Verificar que los términos requeridos estén contenidos en el vocabulario.  \n",
    "\n",
    "2. **Cálculo de vectores de expresión**  \n",
    "   - Construir expresiones vectoriales simples mediante operaciones aritméticas (suma, resta).  \n",
    "\n",
    "3. **Medición de similitud**  \n",
    "   - Calcular la similitud de coseno entre los vectores de la expresión y los vectores de referencia.  \n",
    "   - Reportar:  \n",
    "     - Valor de la similitud de coseno.  \n",
    "     - Normas de cada vector (\\(\\|\\mathbf{u}\\|\\)).  \n",
    "\n",
    "4. **Casos de estudio**  \n",
    "   Realizar caso por caso\n",
    "\n",
    "5. **Documentación de resultados**  \n",
    "   - Registrar en el notebook los valores obtenidos de similitud y normas vectoriales para cada caso.  \n",
    "   - Incluir comentarios breves interpretando los resultados.  \n",
    "\n",
    "6. **Conclusiones**  \n",
    "   - Redactar conclusiones **caso por caso** sobre la utilidad de la similitud de coseno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "znm3REDwDFzf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\caste\\anaconda3\\lib\\site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\caste\\anaconda3\\lib\\site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\caste\\anaconda3\\lib\\site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\caste\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n"
     ]
    }
   ],
   "source": [
    "# Solo si es necesario\n",
    "# !pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "q8Wdrh6SDLE-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NhOrYPOYDfm6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
     ]
    }
   ],
   "source": [
    "# ========= 1) Cargar GloVe 100D =========\n",
    "model = api.load(\"glove-wiki-gigaword-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "MSLOx52ZDQfl"
   },
   "outputs": [],
   "source": [
    "# ========= 2) Funciones utilitarias =========\n",
    "def embedding(word: str) -> np.ndarray:\n",
    "    \"\"\"Vector de la palabra (lanza KeyError si no está en vocab).\"\"\"\n",
    "    return model[word]\n",
    "\n",
    "def build_vector(plus: List[str], minus: List[str]) -> np.ndarray:\n",
    "    \"\"\"Suma y resta embeddings explícitamente.\"\"\"\n",
    "    dim = model[next(iter(model.key_to_index))].shape[0]\n",
    "    v = np.zeros(dim, dtype=np.float32)\n",
    "    for w in plus:\n",
    "        if w in model:\n",
    "            v += model[w]\n",
    "        else:\n",
    "            print(f\"[OOV] '{w}' no está en el vocabulario.\")\n",
    "    for w in minus:\n",
    "        if w in model:\n",
    "            v -= model[w]\n",
    "        else:\n",
    "            print(f\"[OOV] '{w}' no está en el vocabulario.\")\n",
    "    return v\n",
    "\n",
    "def cos(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    na, nb = np.linalg.norm(a), np.linalg.norm(b)\n",
    "    if na == 0 or nb == 0:\n",
    "        return float(\"nan\")\n",
    "    return float(np.dot(a, b) / (na * nb))\n",
    "\n",
    "def vec_norm(v: np.ndarray) -> float:\n",
    "    return float(np.linalg.norm(v))\n",
    "\n",
    "def report_case(label, plus, minus, target_plus):\n",
    "    expr_vec   = build_vector(plus, minus)\n",
    "    target_vec = build_vector(target_plus, [])\n",
    "    print(\"====\", label, \"====\")\n",
    "    print(\"Expresión =\", \" + \".join(plus) + \" - \" + \" - \".join(minus) if minus else \" + \".join(plus))\n",
    "    print(\"Target    =\", \" + \".join(target_plus))\n",
    "    print(\"cos(expr, target) =\", round(cos(expr_vec, target_vec), 6))\n",
    "    print(\"||expr||           =\", round(vec_norm(expr_vec), 6))\n",
    "    print(\"||target||         =\", round(vec_norm(target_vec), 6))\n",
    "    print()\n",
    "\n",
    "def nearest_neighbors(plus: List[str], minus: List[str], topn: int = 3):\n",
    "    \"\"\"Encuentra los vecinos más cercanos a una expresión vectorial.\"\"\"\n",
    "    expr_vec = build_vector(plus, minus)\n",
    "    # calcular similitud con TODO el vocabulario\n",
    "    sims = []\n",
    "    for word in model.index_to_key:\n",
    "        s = cos(expr_vec, model[word])\n",
    "        if not np.isnan(s):\n",
    "            sims.append((word, s))\n",
    "    sims.sort(key=lambda x: -x[1])\n",
    "    return sims[:topn]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYmlGtmYDqd1"
   },
   "source": [
    "## Caso 1 — Capitales\n",
    "\n",
    "Construya un vector que represente la relación:  \n",
    "**paris + italy - france ≈ rome**\n",
    "\n",
    "1. Defina el vector de la expresión (`expr_vec`).  \n",
    "2. Defina el vector objetivo (`target_vec`).  \n",
    "3. Calcule `cos(expr, target)`, `||expr||` y `||target||`.  \n",
    "4. Escriba su conclusión.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Caso 1 ====\n",
      "Expresión = paris + italy - france\n",
      "Target    = rome\n",
      "cos(expr, target) = 0.8084\n",
      "||expr||           = 6.227801\n",
      "||target||         = 5.523363\n",
      "\n"
     ]
    }
   ],
   "source": [
    "expr_vec = build_vector([\"paris\", \"italy\"], [\"france\"])\n",
    "target_vec = build_vector([\"rome\"], [])\n",
    "report_case(\"Caso 1\", [\"paris\", \"italy\"], [\"france\"], [\"rome\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La similitud de coseno obtenida fue 0.8084, lo cual indica una relación bastante fuerte entre el vector construido paris + italy - france y el vector de la palabra rome. Este resultado refleja que los embeddings de GloVe logran capturar correctamente la analogía capital-país, aproximando a Roma como capital de Italia al restar Francia y sumar Italia a París. Además, las normas de los vectores muestran que ambos tienen magnitudes consistentes, lo que da mayor validez a la comparación.\n",
    "\n",
    "En conclusión, este experimento confirma la utilidad de los embeddings para modelar relaciones semánticas complejas a través de simples operaciones vectoriales. El hecho de que el coseno sea mayor a 0.8 demuestra que el modelo ha aprendido de los datos contextuales que Roma se asocia de manera muy cercana a Italia en la misma forma que París lo hace con Francia. Esto muestra cómo la similitud de coseno permite comprobar analogías semánticas de manera cuantitativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wDCO5IIDEjHR"
   },
   "source": [
    "## Caso 2 — Dictador/País\n",
    "\n",
    "Construya un vector que represente la relación:  \n",
    "**hitler + italy - germany**\n",
    "\n",
    "1. Construya el vector de la expresión.  \n",
    "2. Encuentre los **3 vecinos más cercanos** (`nearest_neighbors`).  \n",
    "3. Reporte la similitud coseno con cada vecino.  \n",
    "4. Escriba su interpretación de los resultados.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vecinos más cercanos (palabra, coseno):\n",
      " -       mussolini  0.816139\n",
      " -          hitler  0.715457\n",
      " -         fascist  0.668780\n"
     ]
    }
   ],
   "source": [
    "expr_vec = build_vector([\"hitler\", \"italy\"], [\"germany\"])\n",
    "neighbors = nearest_neighbors([\"hitler\", \"italy\"], [\"germany\"], topn=3)\n",
    "print(\"Vecinos más cercanos (palabra, coseno):\")\n",
    "for w, s in neighbors:\n",
    "    print(f\" - {w:>15s}  {s:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El vector hitler + italy - germany arrojó como vecino más cercano mussolini (0.8161), seguido por hitler (0.7155) y fascist (0.6688). Esto es coherente con la analogía buscada: al “mover” el concepto de Hitler desde Alemania hacia Italia, el espacio semántico se aproxima a Mussolini, líder fascista italiano, con una similitud de coseno alta (>0.81), lo que sugiere que GloVe capturó correctamente la relación “dictador ↔ país”.\n",
    "\n",
    "Que hitler siga apareciendo entre los vecinos indica que la componente semántica de dictador/fascismo domina fuertemente el vector resultante, por lo que parte de la dirección original se conserva. La presencia de fascist como tercer vecino refuerza la dimensión ideológica compartida. En conjunto, los resultados respaldan la utilidad de la similitud de coseno para analogías históricas, aunque también evidencian limitaciones típicas de los embeddings (mezcla de rasgos ideológicos y de entidad) y posibles sesgos del corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IltzpJtcHmYf"
   },
   "source": [
    "## Caso 3 — Religión/Líder\n",
    "\n",
    "Construya un vector que represente la relación:  \n",
    "**christianity ≈ jesus**\n",
    "\n",
    "1. Construya el vector de la palabra `christianity`.  \n",
    "2. Encuentre los **3 vecinos más cercanos** (`nearest_neighbors`).  \n",
    "3. Reporte la similitud coseno con cada vecino.  \n",
    "4. Escriba su interpretación: ¿aparece `jesus` entre los vecinos?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vecinos más cercanos (palabra, coseno):\n",
      " -    christianity  1.000000\n",
      " -     catholicism  0.875112\n",
      " -   protestantism  0.811677\n",
      "\n",
      "¿'jesus' está en top-3?: False\n",
      "cos(christianity, jesus) = 0.542634\n",
      "||christianity|| = 5.906149\n",
      "||jesus||        = 6.103833\n"
     ]
    }
   ],
   "source": [
    "v_christ = build_vector([\"christianity\"], [])\n",
    "\n",
    "neighbors = nearest_neighbors([\"christianity\"], [], topn=3)\n",
    "\n",
    "print(\"Vecinos más cercanos (palabra, coseno):\")\n",
    "for w, s in neighbors:\n",
    "    print(f\" - {w:>15s}  {s:.6f}\")\n",
    "\n",
    "cos_with_jesus = cos(v_christ, embedding(\"jesus\")) if \"jesus\" in model else float(\"nan\")\n",
    "print(\"\\n¿'jesus' está en top-3?:\", any(w==\"jesus\" for w,_ in neighbors))\n",
    "print(\"cos(christianity, jesus) =\", f\"{cos_with_jesus:.6f}\")\n",
    "print(\"||christianity|| =\", f\"{vec_norm(v_christ):.6f}\")\n",
    "print(\"||jesus||        =\", f\"{vec_norm(embedding('jesus')):.6f}\" if \"jesus\" in model else \"N/A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado muestra que los vecinos más cercanos a christianity son catholicism y protestantism, lo cual es coherente, ya que ambos son ramas principales de esta religión. Sin embargo, el término jesus no aparece entre los primeros vecinos y su similitud coseno con christianity es de apenas 0.54, un valor moderado que refleja cierta relación semántica, pero no lo suficientemente fuerte como para ubicarlo entre los más cercanos.\n",
    "\n",
    "Esto indica que el modelo de embeddings representa la palabra christianity principalmente en términos de corrientes religiosas o denominaciones, más que en relación directa con su figura central. Aunque existe un vínculo vectorial con jesus, el contexto estadístico del corpus de entrenamiento de GloVe prioriza asociaciones doctrinales e institucionales. Este resultado evidencia tanto la potencia como las limitaciones de los embeddings al capturar diferentes dimensiones semánticas de un mismo concepto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ylamHudTHtkF"
   },
   "source": [
    "## Caso 4 — Opuestos\n",
    "\n",
    "Analice la relación:  \n",
    "**good - bad**\n",
    "\n",
    "1. Construya el vector de la expresión `good - bad`.  \n",
    "2. Encuentre los **3 vecinos más cercanos** (`nearest_neighbors`).  \n",
    "3. Reporte la similitud coseno con cada vecino.  \n",
    "4. Escriba su conclusión sobre si los vecinos reflejan un contraste u oposición semántica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vecinos más cercanos (palabra, coseno):\n",
      " -       excellent  0.522756\n",
      " -       versatile  0.459313\n",
      " -           ideal  0.457311\n",
      "\n",
      "Cos con 'good' : 0.400063\n",
      "Cos con 'bad'  : -0.276289\n",
      "||expr||       : 3.815561\n"
     ]
    }
   ],
   "source": [
    "expr_vec = build_vector([\"good\"], [\"bad\"])\n",
    "neighbors = nearest_neighbors([\"good\"], [\"bad\"], topn=3)\n",
    "print(\"Vecinos más cercanos (palabra, coseno):\")\n",
    "for w, s in neighbors:\n",
    "    print(f\" - {w:>15s}  {s:.6f}\")\n",
    "print(\"\\nCos con 'good' :\", f\"{cos(expr_vec, embedding('good')):.6f}\")\n",
    "print(\"Cos con 'bad'  :\", f\"{cos(expr_vec, embedding('bad')):.6f}\")\n",
    "print(\"||expr||       :\", f\"{vec_norm(expr_vec):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El vector good - bad produjo vecinos positive-oriented: excellent (0.5228), versatile (0.4593) e ideal (0.4573). Además, su proyección tiene coseno positivo con “good” (0.4001) y negativo con “bad” (−0.2763), lo que indica que la dirección del vector se aleja de lo negativo y se acerca a términos asociados con cualidades deseables. Esto sugiere que la operación efectivamente empuja la representación hacia un eje de “positividad”.\n",
    "\n",
    "Sin embargo, las similitudes son moderadas, no cercanas a 1, lo que evidencia una limitación conocida: los antónimos suelen compartir contextos y, por tanto, pueden quedar relativamente próximos en embeddings distribucionales. En síntesis, good - bad sí refleja contraste semántico (señal clara por el coseno negativo con bad), pero no define un “eje de oposición” perfectamente limpio; para capturarlo mejor se requerirían técnicas como retrofitting/counter-fitting con lexicones de sinonimia/antónimo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_RKNyXiMHySR"
   },
   "source": [
    "## Caso 5 — Propio\n",
    "\n",
    "Defina usted mismo un caso interesante. Ejemplos:  \n",
    "- `king - man + woman`  \n",
    "- `tokyo + france - japan`  \n",
    "- `apple - technology`  \n",
    "\n",
    "1. Construya la expresión vectorial que haya definido.  \n",
    "2. Encuentre los **3 vecinos más cercanos** (`nearest_neighbors`).  \n",
    "3. Reporte la similitud coseno con cada vecino.  \n",
    "4. Redacte una conclusión explicando si los resultados corresponden a su hipótesis inicial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vecinos más cercanos (palabra, coseno):\n",
      " -        facebook  0.669745\n",
      " -          flickr  0.665407\n",
      " -         twitter  0.664536\n",
      " -         myspace  0.663974\n",
      " -         youtube  0.631841\n",
      "\n",
      "cos(expr, 'instagram') = 0.597748\n",
      "||expr||              = 8.155613\n",
      "||'instagram'||         = 5.159590\n"
     ]
    }
   ],
   "source": [
    "expr_vec = build_vector([\"twitter\", \"photos\"], [\"text\"])\n",
    "neighbors = nearest_neighbors([\"twitter\", \"photos\"], [\"text\"], topn=5)\n",
    "\n",
    "print(\"Vecinos más cercanos (palabra, coseno):\")\n",
    "for w, s in neighbors:\n",
    "    print(f\" - {w:>15s}  {s:.6f}\")\n",
    "\n",
    "target = \"instagram\" if \"instagram\" in model else \"flickr\"\n",
    "print(f\"\\ncos(expr, '{target}') =\", f\"{cos(expr_vec, embedding(target)):.6f}\")\n",
    "print(\"||expr||              =\", f\"{vec_norm(expr_vec):.6f}\")\n",
    "if target in model:\n",
    "    print(f\"||'{target}'||         =\", f\"{vec_norm(embedding(target)):.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La expresión twitter + photos − text se desplazó hacia el eje de “redes sociales con fuerte componente visual”: los vecinos fueron facebook (0.6697), flickr (0.6654), twitter (0.6645), myspace (0.6640) y youtube (0.6318), y la similitud con instagram fue 0.5977. Esto sugiere que el vector capturó bien la idea de “plataforma social + énfasis visual”, reflejado en la cercanía a flickr y youtube, mientras aún conserva parte de la identidad de twitter por aparecer entre los vecinos.\n",
    "\n",
    "Que instagram no lidere, pese a un coseno razonable (~0.6), muestra una limitación típica de GloVe: las marcas comparten mucho contexto (“social media”), por lo que el vector mezcla rasgos de varias plataformas. Además, el corpus es antiguo y flickr/myspace pesan más históricamente para “fotos”. Aun así, el resultado apoya parcialmente la hipótesis: el modelo se orienta a “social + visual”, aunque no distingue con precisión fina entre plataformas; para afinar, podrían usarse expresiones más específicas (“photo_sharing”), modelos con sub-palabras (fastText) o embeddings contextuales."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
